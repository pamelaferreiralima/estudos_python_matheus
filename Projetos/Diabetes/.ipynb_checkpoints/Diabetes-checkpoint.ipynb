{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed03a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4aa4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "          tch       ltg       glu    y  \n",
       "0   -0.002592  0.019908 -0.017646  151  \n",
       "1   -0.039493 -0.068330 -0.092204   75  \n",
       "2   -0.002592  0.002864 -0.025930  141  \n",
       "3    0.034309  0.022692 -0.009362  206  \n",
       "4   -0.002592 -0.031991 -0.046641  135  \n",
       "..        ...       ...       ...  ...  \n",
       "437 -0.002592  0.031193  0.007207  178  \n",
       "438  0.034309 -0.018118  0.044485  104  \n",
       "439 -0.011080 -0.046879  0.015491  132  \n",
       "440  0.026560  0.044528 -0.025930  220  \n",
       "441 -0.039493 -0.004220  0.003064   57  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(\"diabetes.rwrite1.txt\", encoding= \"utf_8\", delimiter=\" \")\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.mean(), np.std(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(diabetes['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(diabetes['tc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(diabetes['ldl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674746b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(diabetes['hdl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b17d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(diabetes['glu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5282b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(diabetes, hue = \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observando correlaÃ§Ã£o entre as variÃ¡veis do dataframe\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "corr_mat = diabetes.corr().stack().reset_index(name=\"correlation\")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=corr_mat,\n",
    "    x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n",
    "    palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".7\",\n",
    "    height=10, sizes=(50, 250), size_norm=(-.2, .8),\n",
    ")\n",
    "\n",
    "\n",
    "g.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\n",
    "g.despine(left=True, bottom=True)\n",
    "g.ax.margins(.02)\n",
    "for label in g.ax.get_xticklabels():\n",
    "    label.set_rotation(90)\n",
    "for artist in g.legend.legendHandles:\n",
    "    artist.set_edgecolor(\".7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063697cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "653f5300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionamos as colunas de 1:4 porÃ©m a coluna 4 nÃ£o entrarÃ¡ nessa variÃ¡vel.\n",
    "X = diabetes.iloc[:, 0:10].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8adf7999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151,  75, 141, 206, 135,  97, 138,  63, 110, 310, 101,  69, 179,\n",
       "       185, 118, 171, 166, 144,  97, 168,  68,  49,  68, 245, 184, 202,\n",
       "       137,  85, 131, 283, 129,  59, 341,  87,  65, 102, 265, 276, 252,\n",
       "        90, 100,  55,  61,  92, 259,  53, 190, 142,  75, 142, 155, 225,\n",
       "        59, 104, 182, 128,  52,  37, 170, 170,  61, 144,  52, 128,  71,\n",
       "       163, 150,  97, 160, 178,  48, 270, 202, 111,  85,  42, 170, 200,\n",
       "       252, 113, 143,  51,  52, 210,  65, 141,  55, 134,  42, 111,  98,\n",
       "       164,  48,  96,  90, 162, 150, 279,  92,  83, 128, 102, 302, 198,\n",
       "        95,  53, 134, 144, 232,  81, 104,  59, 246, 297, 258, 229, 275,\n",
       "       281, 179, 200, 200, 173, 180,  84, 121, 161,  99, 109, 115, 268,\n",
       "       274, 158, 107,  83, 103, 272,  85, 280, 336, 281, 118, 317, 235,\n",
       "        60, 174, 259, 178, 128,  96, 126, 288,  88, 292,  71, 197, 186,\n",
       "        25,  84,  96, 195,  53, 217, 172, 131, 214,  59,  70, 220, 268,\n",
       "       152,  47,  74, 295, 101, 151, 127, 237, 225,  81, 151, 107,  64,\n",
       "       138, 185, 265, 101, 137, 143, 141,  79, 292, 178,  91, 116,  86,\n",
       "       122,  72, 129, 142,  90, 158,  39, 196, 222, 277,  99, 196, 202,\n",
       "       155,  77, 191,  70,  73,  49,  65, 263, 248, 296, 214, 185,  78,\n",
       "        93, 252, 150,  77, 208,  77, 108, 160,  53, 220, 154, 259,  90,\n",
       "       246, 124,  67,  72, 257, 262, 275, 177,  71,  47, 187, 125,  78,\n",
       "        51, 258, 215, 303, 243,  91, 150, 310, 153, 346,  63,  89,  50,\n",
       "        39, 103, 308, 116, 145,  74,  45, 115, 264,  87, 202, 127, 182,\n",
       "       241,  66,  94, 283,  64, 102, 200, 265,  94, 230, 181, 156, 233,\n",
       "        60, 219,  80,  68, 332, 248,  84, 200,  55,  85,  89,  31, 129,\n",
       "        83, 275,  65, 198, 236, 253, 124,  44, 172, 114, 142, 109, 180,\n",
       "       144, 163, 147,  97, 220, 190, 109, 191, 122, 230, 242, 248, 249,\n",
       "       192, 131, 237,  78, 135, 244, 199, 270, 164,  72,  96, 306,  91,\n",
       "       214,  95, 216, 263, 178, 113, 200, 139, 139,  88, 148,  88, 243,\n",
       "        71,  77, 109, 272,  60,  54, 221,  90, 311, 281, 182, 321,  58,\n",
       "       262, 206, 233, 242, 123, 167,  63, 197,  71, 168, 140, 217, 121,\n",
       "       235, 245,  40,  52, 104, 132,  88,  69, 219,  72, 201, 110,  51,\n",
       "       277,  63, 118,  69, 273, 258,  43, 198, 242, 232, 175,  93, 168,\n",
       "       275, 293, 281,  72, 140, 189, 181, 209, 136, 261, 113, 131, 174,\n",
       "       257,  55,  84,  42, 146, 212, 233,  91, 111, 152, 120,  67, 310,\n",
       "        94, 183,  66, 173,  72,  49,  64,  48, 178, 104, 132, 220,  57],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = diabetes.iloc[:, 10].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "141e579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando os modelos\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8565b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "  kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "\n",
    "  naive_bayes = GaussianNB()\n",
    "  scores = cross_val_score(naive_bayes, X, y, cv = kfold)\n",
    "  resultados_naive_bayes_cv.append(scores.mean())\n",
    "  \n",
    "  logistica = LogisticRegression()\n",
    "  scores = cross_val_score(logistica, X, y, cv = kfold)\n",
    "  resultados_logistica_cv.append(scores.mean())\n",
    "\n",
    "  random_forest = RandomForestClassifier()\n",
    "  scores = cross_val_score(random_forest, X, y, cv = kfold)\n",
    "  resultados_forest_cv.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8617b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004494949494949494, 0.0022727272727272726, 0.00909090909090909, 0.004545454545454545, 0.0022727272727272726, 0.006767676767676767, 0.011313131313131313, 0.004545454545454545, 0.004545454545454545, 0.004545454545454545, 0.00904040404040404, 0.004494949494949494, 0.004545454545454545, 0.006818181818181818, 0.004494949494949494, 0.006818181818181818, 0.008989898989898989, 0.004494949494949494, 0.006717171717171717, 0.006767676767676767, 0.006818181818181818, 0.00904040404040404, 0.0022727272727272726, 0.006818181818181818, 0.006818181818181818, 0.006818181818181818, 0.004494949494949494, 0.006767676767676767, 0.006767676767676768, 0.004545454545454545, 0.00909090909090909, 0.006818181818181818, 0.004545454545454545, 0.004545454545454545, 0.004494949494949494, 0.00904040404040404, 0.004545454545454545, 0.0022727272727272726, 0.006767676767676768, 0.006818181818181818, 0.011363636363636364, 0.006767676767676768, 0.013484848484848483, 0.004494949494949494, 0.004494949494949494, 0.006818181818181818, 0.0022727272727272726, 0.0, 0.006818181818181818, 0.004494949494949494, 0.00909090909090909, 0.004545454545454545, 0.006767676767676768, 0.0022727272727272726]\n",
      "[0.004545454545454545, 0.004494949494949494, 0.006818181818181818, 0.006818181818181818, 0.006818181818181818, 0.004545454545454545, 0.00909090909090909, 0.0, 0.006818181818181818, 0.006818181818181818, 0.0022222222222222222, 0.0022727272727272726, 0.006767676767676768, 0.0, 0.0022727272727272726, 0.004545454545454545, 0.004545454545454545, 0.0022727272727272726, 0.00909090909090909, 0.0044444444444444444, 0.0022727272727272726, 0.0, 0.011212121212121211, 0.006818181818181818, 0.006818181818181818, 0.004545454545454545, 0.004494949494949494, 0.006818181818181818, 0.006818181818181818, 0.006818181818181818, 0.004545454545454545, 0.00909090909090909, 0.0, 0.006818181818181818, 0.006818181818181818, 0.0022222222222222222, 0.0022727272727272726, 0.006767676767676768, 0.0, 0.0022727272727272726, 0.004545454545454545, 0.004545454545454545, 0.0022727272727272726, 0.00909090909090909, 0.0044444444444444444, 0.0022727272727272726, 0.0, 0.011212121212121211, 0.006818181818181818, 0.006818181818181818, 0.006767676767676768, 0.004545454545454545, 0.006818181818181818, 0.00909090909090909, 0.0022727272727272726]\n",
      "[0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.004545454545454545, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.004494949494949494, 0.0022727272727272726, 0.004545454545454545, 0.0022222222222222222, 0.004494949494949494, 0.0, 0.004545454545454545, 0.0022222222222222222, 0.004494949494949494, 0.004545454545454545, 0.0022727272727272726, 0.0022222222222222222, 0.0044444444444444444, 0.0022727272727272726, 0.004545454545454545, 0.004545454545454545, 0.004494949494949494, 0.0022727272727272726, 0.0, 0.004545454545454545, 0.00904040404040404, 0.004545454545454545, 0.0022727272727272726, 0.0022727272727272726, 0.0022727272727272726, 0.004494949494949494, 0.0022727272727272726, 0.004545454545454545, 0.0022222222222222222, 0.004494949494949494, 0.0, 0.004545454545454545, 0.0022222222222222222, 0.004494949494949494, 0.004545454545454545, 0.0022727272727272726, 0.0022222222222222222, 0.0044444444444444444, 0.0022727272727272726, 0.004545454545454545, 0.004545454545454545, 0.004494949494949494, 0.0022727272727272726, 0.0, 0.004545454545454545, 0.00904040404040404, 0.0022727272727272726, 0.006818181818181818, 0.0022727272727272726, 0.004545454545454545, 0.0022727272727272726]\n"
     ]
    }
   ],
   "source": [
    "print(resultados_forest_cv)\n",
    "print(resultados_logistica_cv)\n",
    "print(resultados_naive_bayes_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1e7d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "867097fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151\n",
       "1       75\n",
       "2      141\n",
       "3      206\n",
       "4      135\n",
       "      ... \n",
       "437    178\n",
       "438    104\n",
       "439    132\n",
       "440    220\n",
       "441     57\n",
       "Name: y, Length: 442, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.iloc[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a130408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes.fit(X, y)\n",
    "logistica.fit(X, y)\n",
    "random_forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c0b0aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([263, 134, 138, 206, 214,  64,  71, 138, 110, 258, 101, 138, 134,\n",
       "       138, 134, 171, 166, 196, 160, 134, 134,  71, 134, 245, 184, 124,\n",
       "        59, 140, 134, 283, 134,  59, 341,  87, 134, 102, 134, 276, 217,\n",
       "       116, 100, 134,  61, 103, 138, 110, 134, 134,  75, 138, 134, 138,\n",
       "       128, 113, 134, 134, 128,  37, 103, 107,  61, 116,  39,  64,  71,\n",
       "       163, 107, 107, 160, 134,  48, 270, 138, 196, 217, 107, 138, 134,\n",
       "       152, 113, 143, 196, 134, 210,  48, 134, 116, 134,  71, 134,  98,\n",
       "       164,  48,  48, 134, 162, 196, 279,  71, 214,  95, 102, 302, 196,\n",
       "       134, 160, 134, 140, 232, 245,  71, 191, 246, 297, 258, 229, 196,\n",
       "       258, 196, 134, 182, 173, 180,  84, 134, 161,  99, 109, 134, 173,\n",
       "       274, 134, 107,  71, 134, 272,  59, 280, 336, 258, 107, 317, 235,\n",
       "       134, 174, 134, 196, 128, 107, 126, 288, 134, 217, 110, 197, 186,\n",
       "        25, 107,  64, 195, 134, 217, 140, 217, 134, 134,  70, 173, 268,\n",
       "       152,  47, 134, 295,  70, 116, 134, 237, 258, 134, 214, 196,  64,\n",
       "       138, 110, 128, 138, 138, 143, 143,  79, 214,  71,  71, 116,  86,\n",
       "       196, 128, 196, 134, 152, 158,  49, 196, 222, 277,  99, 196,  95,\n",
       "       155, 138, 191, 134,  73, 134,  64, 263, 217, 296, 214, 134,  71,\n",
       "       214,  71, 134, 134, 208,  71, 108, 160,  49, 220, 154, 107, 134,\n",
       "       246, 124, 258, 158, 138, 128, 164, 177,  71,  47, 187, 125, 115,\n",
       "       134, 258, 215, 303, 243, 128, 173, 217, 153, 346,  71,  89,  50,\n",
       "       182, 103, 308, 116, 145,  71,  45, 115, 264,  87, 217, 127, 140,\n",
       "       241, 190,  71, 283,  64, 102,  71, 107, 116, 230, 134, 156, 152,\n",
       "        64, 115,  80, 116, 332, 258,  59, 128,  71, 116, 134,  31,  71,\n",
       "        71, 128, 107, 258, 236, 253, 124,  44, 131, 114, 217, 258, 180,\n",
       "       134, 163, 147, 134, 196, 190, 134, 191, 258, 230, 217, 248, 249,\n",
       "       192, 164, 237, 140,  49, 244, 199, 270, 164,  71, 134, 306, 196,\n",
       "       214,  95, 216, 263, 110, 113, 115, 196, 139,  71, 148,  88, 243,\n",
       "        71,  77, 258, 196,  71,  54, 221,  59, 311, 258, 182, 321,  58,\n",
       "       262, 206, 233, 242, 123, 167, 134, 197,  71, 134, 134, 217, 121,\n",
       "       235, 196,  40, 182, 116, 132,  71, 138,  71, 134, 201, 110,  51,\n",
       "       277, 134,  71, 134, 273, 128,  43, 190, 128, 232, 175,  93, 124,\n",
       "       258, 293, 281, 134, 140, 189, 138, 209, 136, 261, 113, 139, 174,\n",
       "       258, 140,  64, 134, 146, 212, 217, 138, 196, 152, 120,  70, 217,\n",
       "        59, 183,  71, 173, 134, 113, 160,  48, 110, 116,  71, 173,  57],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6485d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200,  72, 200, 200,  72,  72,  72,  72, 200, 200,  72, 200,  72,\n",
       "       200,  72, 200, 200, 200, 200,  72,  72,  72,  72, 200, 200, 200,\n",
       "        72, 200,  72,  72, 200,  72, 200,  72,  72,  72, 200,  72, 200,\n",
       "        72, 200,  72, 200,  72, 200,  72,  72,  72,  72, 200,  72, 200,\n",
       "        72, 200,  72,  72, 200,  72,  72,  72,  72, 200,  72,  72,  72,\n",
       "       200, 200,  72,  72,  72,  72, 200,  72,  72, 200,  72, 200,  72,\n",
       "        72,  72,  72,  72,  72,  72,  72,  72,  72,  72,  72,  72,  72,\n",
       "       200, 200,  72,  72,  72, 200, 200,  72,  72,  72,  72, 200, 200,\n",
       "       200,  72,  72, 200, 200, 200,  72,  72, 200, 200, 200, 200, 200,\n",
       "       200, 200,  72, 200, 200, 200, 200,  72, 200,  72,  72,  72, 200,\n",
       "       200,  72,  72,  72,  72, 200,  72, 200, 200, 200, 200, 200, 200,\n",
       "        72, 200, 200, 200, 200, 200, 200, 200,  72, 200,  72,  72, 200,\n",
       "        72,  72,  72, 200,  72, 200, 200, 200,  72,  72,  72, 200, 200,\n",
       "       200,  72,  72, 200,  72, 200,  72, 200, 200,  72, 200, 200,  72,\n",
       "       200, 200, 200, 200, 200,  72,  72,  72, 200,  72,  72, 200, 200,\n",
       "       200,  72, 200, 200,  72,  72,  72, 200, 200, 200, 200, 200, 200,\n",
       "       200, 200,  72,  72,  72,  72,  72, 200, 200, 200,  72,  72,  72,\n",
       "        72, 200,  72,  72, 200,  72,  72,  72,  72, 200,  72, 200,  72,\n",
       "       200, 200, 200,  72, 200, 200, 200,  72,  72,  72, 200,  72,  72,\n",
       "        72, 200, 200, 200, 200, 200, 200, 200,  72, 200,  72, 200,  72,\n",
       "        72,  72, 200,  72, 200,  72,  72,  72, 200,  72, 200, 200,  72,\n",
       "       200, 200, 200, 200,  72,  72,  72, 200,  72,  72,  72,  72, 200,\n",
       "        72,  72,  72, 200, 200, 200,  72, 200,  72, 200,  72,  72,  72,\n",
       "        72, 200,  72, 200, 200, 200, 200,  72, 200,  72, 200, 200, 200,\n",
       "        72, 200, 200,  72, 200, 200,  72,  72, 200, 200, 200, 200, 200,\n",
       "       200, 200, 200, 200,  72, 200,  72, 200, 200,  72,  72, 200, 200,\n",
       "        72,  72, 200, 200, 200, 200, 200,  72, 200,  72,  72,  72, 200,\n",
       "        72,  72, 200, 200, 200,  72, 200,  72, 200, 200,  72, 200, 200,\n",
       "       200,  72, 200, 200, 200, 200,  72, 200,  72, 200,  72, 200, 200,\n",
       "       200, 200,  72, 200,  72, 200,  72,  72,  72,  72,  72,  72,  72,\n",
       "       200,  72, 200,  72, 200, 200,  72,  72,  72, 200, 200,  72,  72,\n",
       "       200, 200, 200,  72, 200, 200, 200, 200,  72, 200,  72, 200, 200,\n",
       "       200, 200,  72,  72, 200, 200, 200, 200, 200,  72, 200, 200, 200,\n",
       "        72,  72,  72, 200,  72,  72,  72,  72, 200, 200,  72, 200,  72],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistica.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7b1dba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151,  75, 141, 206, 135,  97, 138,  63, 110, 310, 101,  69, 179,\n",
       "       185, 118, 171, 166, 144,  97, 168,  68,  49,  68, 245, 184, 202,\n",
       "       137,  85, 131, 283, 129,  59, 341,  87,  65, 102, 265, 276, 252,\n",
       "        90, 100,  55,  61,  92, 259,  53, 190, 142,  75, 142, 155, 225,\n",
       "        59, 104, 182, 128,  52,  37, 170, 170,  61, 144,  52, 128,  71,\n",
       "       163, 150,  97, 160, 178,  48, 270, 202, 111,  85,  42, 170, 200,\n",
       "       252, 113, 143,  51,  52, 210,  65, 141,  55, 134,  42, 111,  98,\n",
       "       164,  48,  96,  90, 162, 150, 279,  92,  83, 128, 102, 302, 198,\n",
       "        95,  53, 134, 144, 232,  81, 104,  59, 246, 297, 258, 229, 275,\n",
       "       281, 179, 200, 200, 173, 180,  84, 121, 161,  99, 109, 115, 268,\n",
       "       274, 158, 107,  83, 103, 272,  85, 280, 336, 281, 118, 317, 235,\n",
       "        60, 174, 259, 178, 128,  96, 126, 288,  88, 292,  71, 197, 186,\n",
       "        25,  84,  96, 195,  53, 217, 172, 131, 214,  59,  70, 220, 268,\n",
       "       152,  47,  74, 295, 101, 151, 127, 237, 225,  81, 151, 107,  64,\n",
       "       138, 185, 265, 101, 137, 143, 141,  79, 292, 178,  91, 116,  86,\n",
       "       122,  72, 129, 142,  90, 158,  39, 196, 222, 277,  99, 196, 202,\n",
       "       155,  77, 191,  70,  73,  49,  65, 263, 248, 296, 214, 185,  78,\n",
       "        93, 252, 150,  77, 208,  77, 108, 160,  53, 220, 154, 259,  90,\n",
       "       246, 124,  67,  72, 257, 262, 275, 177,  71,  47, 187, 125,  78,\n",
       "        51, 258, 215, 303, 243,  91, 150, 310, 153, 346,  63,  89,  50,\n",
       "        39, 103, 308, 116, 145,  74,  45, 115, 264,  87, 202, 127, 182,\n",
       "       241,  66,  94, 283,  64, 102, 200, 265,  94, 230, 181, 156, 233,\n",
       "        60, 219,  80,  68, 332, 248,  84, 200,  55,  85,  89,  31, 129,\n",
       "        83, 275,  65, 198, 236, 253, 124,  44, 172, 114, 142, 109, 180,\n",
       "       144, 163, 147,  97, 220, 190, 109, 191, 122, 230, 242, 248, 249,\n",
       "       192, 131, 237,  78, 135, 244, 199, 270, 164,  72,  96, 306,  91,\n",
       "       214,  95, 216, 263, 178, 113, 200, 139, 139,  88, 148,  88, 243,\n",
       "        71,  77, 109, 272,  60,  54, 221,  90, 311, 281, 182, 321,  58,\n",
       "       262, 206, 233, 242, 123, 167,  63, 197,  71, 168, 140, 217, 121,\n",
       "       235, 245,  40,  52, 104, 132,  88,  69, 219,  72, 201, 110,  51,\n",
       "       277,  63, 118,  69, 273, 258,  43, 198, 242, 232, 175,  93, 168,\n",
       "       275, 293, 281,  72, 140, 189, 181, 209, 136, 261, 113, 131, 174,\n",
       "       257,  55,  84,  42, 146, 212, 233,  91, 111, 152, 120,  67, 310,\n",
       "        94, 183,  66, 173,  72,  49,  64,  48, 178, 104, 132, 220,  57],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
